Siamo oramai in un'era in cui l'intelligenza artificiale è presente in ogni aspetto della nostra vita digitale,
ancora di più dopo l'uscita a fine 2022 di ChatGPT, che infranse il record di applicazione con la più rapida crescita nella storia di Internet,
ben 100 milioni di utenti in soli 2 mesi \cite{ubs2023latest}, che fece crescere l'interesse per l'intelligenza
artificiale generativa, capace cioè di generare testi, audio, immagini o video a partire da un semplice “prompt” dell'utente. \\
Di particolare interesse sono le IA capaci di generare testo, i cosiddetti \textit{Large Language Models} (LLM), letteralmente modelli linguistici
di grandi dimensioni, in grado di emulare con sorprendente accuratezza le capacità conversazionali di un essere umano. Un'interessante
conseguenza del modo in cui questi algoritmi sono stati creati, ma soprattutto della mole di dati usata per addestrarli, è stato l'emergere
di comportamenti che potremmo considerare intelligenti, con un livello quasi pari a quello di un essere umano. Ad esempio, gli LLM sono
in grado di ricordare informazioni, generare risposte articolate basate su un ampio contesto e ragionare su problemi complessi derivanti
dalle branche più disparate, dalla meccanica quantistica alla biologia evolutiva. \\
Negli ultimi anni è nato il desiderio di rendere ancora più sofisticate le abilità di questi modelli linguistici, finora relegate al
“semplice” rispondere ai messaggi degli utenti. Ed è per questo che Anthropic, una delle maggiori aziende nel settore della ricerca sugli LLM
e creatrice dei molto diffusi modelli Claude, ha ideato un meccanismo che facilita questo obiettivo: il Model Context Protocol (MCP).
Questo protocollo open-source definisce una procedura standard che consente alle applicazioni di fornire contesto ai modelli linguistici,
permettendo loro di accedere a e interagire con una serie di strumenti esterni in modo sicuro e controllato. Grazie a ciò, gli LLM possono
eseguire operazioni specifiche, recuperare informazioni o integrare funzionalità aggiuntive, migliorando l'efficacia e la personalizzazione
delle risposte generate \cite{modelcontextprotocol2024}. \\
La seguente tesi sarà così strutturata:
\begin{itemize}
    \item \textbf{Capitolo 1}: discussione nel dettaglio degli LLM, dalla loro struttura e funzionamento alle strategie che vengono
    usate dai ricercatori per renderli così sofisticati, oltre alle limitazioni di questi algoritmi e le sfide derivanti dalla loro diffusione.
    \item \textbf{Capitolo 2}: introduzione al Model Context Protocol di Anthropic.
    \item \textbf{Capitolo 3}: discussione sul progetto centrale di questa tesi, il \textit{Ticket Management System}, volto a dimostrare
    nella pratica le funzionalità del Model Context Protocol. Il progetto in questione è un sistema software che consente agli utenti di
    interfacciarsi con un chatbot, rendendo più naturale la creazione di ticket che descrivono i problemi riscontrati e l'inoltro degli stessi
    a degli sviluppatori che possono visionarli e avviare delle procedure per risolverli. Verrà inclusa una conversazione esempio tratta
    dall'interazione con il chatbot, per dimostrare il corretto funzionamento del sistema.
\end{itemize}
Infine, seguirà una discussione sulle limitazioni del progetto e sulle prospettive future. In particolare, l'integrazione del
\textit{Ticket Management System} nel sistema software 3FS{\textsuperscript{\tiny\textcopyright}}.