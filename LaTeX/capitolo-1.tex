\chapter{Large Language Model - Cosa sono e come funzionano}

\widefigure[1.2\textwidth]
    {../figure/llms-timeline.png}{
        Cronologia dei principali \textit{Large Language Models} (LLM) sviluppati fino al 2024.
        Sopra la linea ci sono i modelli open-source, mentre sotto ci sono quelli closed-source.
        \cite{arxiv230706435}
    }{fig:llms-timeline}

\section{Introduzione}

Il linguaggio rappresenta uno strumento fondamentale per gli esseri umani, sia come mezzo di comunicazione e trasmissione di conoscenza,
sia come interfaccia per interagire con le macchine. Lo sviluppo di modelli linguistici sempre più potenti è stato quindi al centro
della ricerca in \textit{Natural Language Processing} (NLP).

Storicamente, si è passati da approcci statistici (basati su n-grammi e modelli probabilistici), a modelli neurali, con una struttura ispirata
a quella del cervello, fino ai modelli pre-addestrati (\textit{Pre-trained Language Models}, PLM).
Quest'ultimi, addestrati su grandi corpus testuali, hanno introdotto il concetto di rappresentazioni generali del linguaggio,
successivamente adattabili tramite \textit{fine-tuning} a specifici compiti \cite{devlin2019bert}\cite{peters2018elmo}\cite{lewis2019bart}.

Un punto di svolta è stato l'introduzione dei \textbf{\textit{Transformer}} \cite{chernyavskiy2021transformers},
che hanno reso possibile scalare i modelli a miliardi di parametri grazie al meccanismo di attenzione,
alla parallelizzazione e alla disponibilità di hardware e dataset sempre più estesi.
Questo ha portato alla nascita dei \textbf{Large Language Models} (LLM).

\newpage
\section{Funzionamento}

Illustriamo ora i concetti fondamentali per comprendere
la struttura e il funzionamento dei \textit{Large Language Models} (LLM).

\subsection{Panoramica}
Il testo dell'utente, il cosiddetto \textit{prompt}, viene prima pre-processato e ridotto in \textit{token}, ossia diviso in frammenti più piccoli,
i quali vengono poi trasformati in rappresentazioni numeriche che attraversano una rete neurale particolare chiamata Transformer, basata
su meccanismi di attenzione, che restituisce un singolo token, che viene poi riconvertito in una parola. Il testo iniziale con l'aggiunta del token
generato viene poi dato in input all'LLM per generare un nuovo token e così via. Infine il modello viene addestrato, cioè i suoi parametri vengono
strategicamente modificati, per generare risposte sensate e coerenti.
Le diverse scelte in ciascuna di queste fasi (tokenizzazione, qualità dei dati, obiettivo di training, architettura)
determinano in gran parte le capacità e i limiti del modello.

\subsection{Tokenizzazione e pre-processing dei dati}
La tokenizzazione \cite{webster1992tokenization} spezza il testo in unità elementari chiamate token: possono essere singoli caratteri,
sottoparole \cite{kudo2018subword}, simboli \cite{sennrich2016neural} o parole complete. Prima della tokenizzazione
si eseguono operazioni di pre-processing: filtraggio della qualità, deduplicazione e rimozione di informazioni sensibili.
Un buon pre-processing dei dati riduce inoltre rumore, bias e contenuti non desiderati, migliorando la generalizzazione del modello.

\subsection{Il Transformer: principio e componenti fondamentali}
Il Transformer è l'architettura alla base degli LLM moderni. Si basa su un principio chiamato \textit{self-attention} \cite{vaswani2017attention}:
nel rappresentare matematicamente i token del prompt, trasformandoli in oggetti chiamati \textit{embeddings}, si tiene conto non solo della parola
isolata ma anche dell'intera frase nella quale si trova, aggiungendo così il contesto.

Ci sono poi diverse tipologie di Transformer:
\begin{itemize}
    \item \textbf{\textit{Encoder-decoder}}: due parti separate, una legge l'input (\textit{encoder}) e l'altra genera l'output (\textit{decoder}).
    Utile per traduzione o riassunti.
    \item \textbf{\textit{Decoder autoregressivo}}: genera una parola alla volta guardando solo le parole già prodotte (utilizzato nei modelli GPT).
    \item \textbf{\textit{Mixture-of-Experts (MoE)}}: il modello ha molti "esperti" specializzati e per ogni input ne attiva solo alcuni,
    migliorando così l'efficienza \cite{fedus2022switch}\cite{du2022glam}\cite{ren2023pangu-p}.
\end{itemize}

\subsection{Stadi di adattamento: dal pre-training all'uso}
Il ciclo di vita di un LLM si articola tipicamente in tre fasi principali:
\begin{enumerate}
    \item \textbf{Pre-training}: apprendimento auto-supervisionato su grandi corpus testuali per acquisire conoscenze linguistiche generali.
    \item \textbf{Fine-tuning / Alignment}: adattamento a compiti specifici o preferenze umane.
    \item \textbf{Prompting / Utilizzo}: impiego diretto tramite prompt.
\end{enumerate}

\newpage
\section{\textit{Pre-training}}

Il \textbf{\textit{pre-training}} è la fase cruciale che consente ai Large Language Models (LLM) di acquisire conoscenza linguistica generale e capacità di 
rappresentazione del testo prima di qualsiasi adattamento specifico.

\subsection{Obiettivi di pre-training}
Gli obiettivi di addestramento definiscono cosa il modello apprende:
\begin{itemize}
    \item \textbf{\textit{Full Language Modeling}}: al modello viene chiesto di predire i token futuri dati i token precedenti.
    \item \textbf{\textit{Prefix Language Modeling}}: un insieme di alcuni token viene scelto casualmente e solo i token rimanenti
    devono essere previsti dal modello correttamente.
    \item \textbf{\textit{Masked Language Modeling}}: i token, o gli span (una sequenza di token), vengono mascherati casualmente e al modello
    viene chiesto di predire i token mascherati dato il contesto intorno a loro.
    \cite{wang2022what}
\end{itemize}

\subsection{Dataset di Addestramento}
La qualità e la varietà dei dati di pre-training sono fondamentali. Le principali categorie di dataset includono:
\begin{itemize}
    \item \textbf{Corpus web}: testi raccolti da siti web, ad esempio \textit{Common Crawl}.
    \item \textbf{Enciclopedie e risorse strutturate}, come Wikipedia.
    \item \textbf{Libri e testi lunghi}, ad esempio \textit{BooksCorpus}.
    \item \textbf{Forum e codice}, inclusi dataset come \textit{The Pile}, \textit{Github}, \textit{StackExchange}.
\end{itemize}
Prima dell'addestramento, i dataset subiscono processi di filtraggio e deduplicazione.

\subsection{Sfide del Pre-training}
L'addestramento degli LLM pone sfide di tipo computazionale e metodologico:
\begin{itemize}
    \item \textbf{Costo computazionale}: i modelli con centinaia di miliardi di parametri richiedono settimane di addestramento su supercomputer 
    con migliaia di GPU.
    \item \textbf{Efficienza dei dati}: la disponibilità di dati di alta qualità è limitata.
    \item \textbf{Rumore e bias}: i dati web contengono rumore, contenuti tossici e bias culturali che vengono appresi dal modello.
    \item \textbf{Controllo della qualità}: è necessario implementare filtri e curare la selezione delle fonti.
\end{itemize}

\newpage
\section{Fine-tuning e Adattamento}

Dopo il pre-training, gli LLM vengono tipicamente sottoposti a una fase di adattamento, che ne affina le capacità su compiti specifici o 
ne migliora l'allineamento con le intenzioni umane.

\subsection{\textit{Supervised Fine-tuning} (SFT)}
Consiste nell'addestrare ulteriormente l'LLM su un dataset etichettato per compiti specifici (es. traduzione, classificazione, QA).
\begin{itemize}
    \item Viene usato per adattare un modello generalista a un dominio ristretto (es. medicina, diritto).
    \item Può essere effettuato con dataset relativamente piccoli rispetto al pre-training.
    \item Rischia di causare \textit{catastrophic forgetting}, ossia perdita delle conoscenze generali.
\end{itemize}

\subsection{\textit{Instruction Tuning}}
Gli LLM vengono ottimizzati per comprendere e seguire istruzioni in linguaggio naturale.
\begin{itemize}
    \item Basato su dataset di tipo \textit{prompt-response}, costruiti manualmente o tramite crowdsourcing.
    \item Introduce la capacità di rispondere in modo coerente a comandi generali senza ulteriori adattamenti.
\end{itemize}
\cite{chung2022scaling}

\subsection{\textit{Reinforcement Learning from Human Feedback (RLHF)}}
Il \textbf{RLHF} \cite{ziegler2019fine} rappresenta una tecnica fondamentale per allineare i modelli alle preferenze umane.
\begin{enumerate}
    \item Si raccoglie un dataset di risposte generate dal modello valutate da esseri umani.
    \item Si addestra un modello di reward che impara a prevedere la valutazione di cui prima.
    \item L'LLM viene ulteriormente ottimizzato con tecniche di reinforcement learning.
\end{enumerate}
Questo approccio è stato utilizzato, ad esempio, per ChatGPT.

\subsection{\textit{Domain Adaptation}}
Gli LLM possono essere specializzati in domini specifici:
\begin{itemize}
    \item \textbf{\textit{Continued Pre-training}}: ulteriore addestramento su corpus specializzati.
    \item \textbf{\textit{Fine-tuning} supervisionato su task di dominio}.
    \item \textbf{Approcci ibridi}: combinazioni di pre-training e PEFT (\textit{Parameter-Efficient Fine-Tuning}).
\end{itemize}

\subsection{\textit{Alignment Tuning}}
Per garantire sicurezza, utilità e rispetto delle preferenze etiche,
si introducono strategie di \textit{alignment}:
\begin{itemize}
    \item \textbf{\textit{Constitutional AI}}: uso di principi predefiniti come linee guida per il comportamento del modello.
    \item \textbf{\textit{Self-critique} e revisione}: i modelli generano e valutano autonomamente le proprie risposte. \cite{touvron2023llama2}\cite{ouyang2022rlhf}
\end{itemize}

\widefigure[1.2\textwidth]
    {../figure/llms-stages.png}{
        \cite{arxiv230706435}
    }{fig:llms-stages}

\newpage
\section{Tecniche di Prompting e In-Context Learning}

\subsection{Zero-shot Prompting}
Nel \textbf{\textit{zero-shot prompting}} il modello riceve soltanto una descrizione del compito
in linguaggio naturale, senza esempi.
\begin{itemize}
    \item Dimostra la capacità di generalizzazione appresa durante il pre-training.
    \item Funziona bene per compiti semplici e largamente rappresentati nei dati di training.
    \item È la modalità più naturale di interazione con un LLM.
\end{itemize}

\subsection{Few-shot Prompting e In-Context Learning (ICL)}
Nel \textbf{few-shot prompting}, al modello vengono forniti alcuni esempi 
di input-output all'interno del prompt. Consente al modello di inferire lo schema del compito e adattarsi in tempo reale.
Questo comportamento è noto come \textbf{\textit{in-context learning}} (ICL) \cite{dong2023survey}.

\subsection{Prompt Engineering}
La formulazione del prompt influenza drasticamente la qualità delle risposte.
Sono dunque emerse tecniche sistematiche di \textbf{prompt engineering}:
\begin{itemize}
    \item \textbf{Instruction-style prompts}: forniscono istruzioni chiare e contestualizzate.
    \item \textbf{Template-based prompting}: utilizzo di schemi predefiniti per generare input coerenti.
    \item \textbf{Role prompting}: assegnazione di un “ruolo” al modello (es. “Sei un medico con decenni di esperienza…”).
\end{itemize}

\subsection{Prompting per il Ragionamento}
Gli LLM possono essere spinti a mostrare capacità di ragionamento tramite prompt opportuni.
Le tecniche principali sono:
\begin{itemize}
    \item \textbf{\textit{Chain-of-Thought} (CoT)}: incoraggia il modello a produrre spiegazioni passo-passo \cite{wei2022chain}.
    \item \textbf{\textit{Self-Consistency}}: genera più catene di ragionamento e seleziona la risposta più frequente \cite{wang2022selfconsistency}.
    \item \textbf{\textit{Tree-of-Thought} (ToT)}: esplora diversi percorsi di ragionamento, con possibilità di backtracking \cite{yao2023tree}.
    \item \textbf{\textit{Generated Knowledge Prompting}}: il modello produce prima conoscenza di supporto, poi la usa per rispondere.
\end{itemize}

\subsection{Multi-turn Prompting}
Alcuni compiti complessi richiedono interazioni iterative con il modello.
\begin{itemize}
    \item \textbf{\textit{Single-turn prompting}}: il modello riceve tutte le informazioni in un unico prompt.
    \item \textbf{\textit{Multi-turn prompting}}: l'interazione è suddivisa in più turni, 
    con feedback e aggiustamenti progressivi. Questo approccio è alla base degli \textbf{agenti autonomi} basati su LLM.
\end{itemize}

\subsection{Tecniche Avanzate di Prompting}
Sono state sviluppate ulteriori strategie per aumentare l'affidabilità:
\begin{itemize}
    \item \textbf{\textit{Prompt Chaining}}: suddividere un compito complesso in più sotto-compiti concatenati.
    \item \textbf{\textit{Automatic Prompt Generation}}: generazione automatica di prompt efficaci 
    tramite ottimizzazione o meta-modelli.
    \item \textbf{\textit{Retrieval-Augmented Prompting}}: combinazione con sistemi di recupero documentale 
    per fornire contesto aggiornato e ridurre le allucinazioni.
\end{itemize}

\newpage
\section{Applicazioni}

Gli \textbf{Large Language Models} (LLM) hanno trovato applicazioni in un'ampia gamma di domini, 
dalla generazione di linguaggio naturale alla programmazione, 
dalla ricerca scientifica alla medicina. 
Questo capitolo presenta le principali aree di utilizzo e gli scenari emergenti.

\subsection{Generazione e Comprensione del Linguaggio Naturale}
Gli LLM eccellono in compiti tradizionali di NLP:
\begin{itemize}
    \item \textbf{Traduzione automatica}: modelli come GPT, T5 e mBART hanno raggiunto 
    performance vicine ai sistemi dedicati.
    \item \textbf{Riassunto testuale}: generazione di sintesi coerenti e concise da testi lunghi.
    \item \textbf{Parafrasi e riformulazione}: utile per la scrittura assistita e l'elaborazione creativa.
    \item \textbf{Conversazione e chatbot}: applicazioni come \textit{ChatGPT} e Claude 
    forniscono assistenza virtuale multi-dominio.
\end{itemize}

\subsection{Programmazione e Ingegneria del Software}
Gli LLM specializzati sul codice hanno mostrato grande impatto nello sviluppo software:
\begin{itemize}
    \item \textbf{Code completion}: completamento automatico di funzioni e snippet.
    \item \textbf{Code generation}: traduzione da linguaggio naturale a codice eseguibile.
    \item \textbf{Code explanation e refactoring}: spiegazione e ottimizzazione di codice esistente.
    \item Strumenti come \textit{Codex}, \textit{Copilot} e \textit{AlphaCode} hanno reso accessibile 
    la programmazione anche a utenti non esperti.
\end{itemize}

\subsection{Supporto alla Ricerca e alla Scienza}
Gli LLM vengono sempre più utilizzati come strumenti di accelerazione scientifica:
\begin{itemize}
    \item \textbf{Recupero e sintesi della letteratura scientifica}.
    \item \textbf{Generazione di ipotesi}: suggerimenti per esperimenti o linee di ricerca.
    \item \textbf{Analisi dati e interpretazione}: supporto a scienziati in fisica, biologia, chimica.
    \item \textbf{Scoperta di molecole e farmaci}: integrazione con modelli di chimica computazionale.
\end{itemize}

\subsection{Medicina e Assistenza Sanitaria}
Il settore medico rappresenta un campo sensibile ma promettente:
\begin{itemize}
    \item \textbf{Supporto diagnostico}: analisi di sintomi e cartelle cliniche.
    \item \textbf{Assistenza alla scrittura clinica}: redazione automatica di referti.
    \item \textbf{Educazione medica}: generazione di materiali di studio personalizzati.
    \item \textbf{Chatbot sanitari}: fornire informazioni mediche preliminari ai pazienti.
\end{itemize}
Sono necessarie forti misure di sicurezza per ridurre rischi di allucinazioni e bias.

\subsection{Educazione e Apprendimento}
Gli LLM possono agire da tutor personalizzati:
\begin{itemize}
    \item \textbf{Creazione di materiali didattici adattivi}.
    \item \textbf{Assistenza individuale agli studenti} con spiegazioni su misura.
    \item \textbf{Valutazione automatizzata} di esercizi e saggi.
    \item Supporto all'apprendimento delle lingue attraverso dialoghi interattivi.
\end{itemize}

\subsection{Business e Produttività}
Le applicazioni aziendali sono tra le più immediate:
\begin{itemize}
    \item \textbf{Automazione del customer service} con chatbot multilingue.
    \item \textbf{Generazione di report e analisi} a partire da dati aziendali.
    \item \textbf{Supporto alle decisioni} tramite analisi predittive.
    \item \textbf{Content creation}: marketing, copywriting e produzione di contenuti digitali.
\end{itemize}

\subsection{Applicazioni Multimodali}
Gli LLM vengono estesi per gestire input multimodali:
\begin{itemize}
    \item \textbf{\textit{Vision-Language Models}}, come \textit{CLIP}, \textit{Flamingo}, GPT-4 multimodale.
    \item \textbf{Image captioning e visual question answering}.
    \item \textbf{Audio e speech}: trascrizione, traduzione e sintesi vocale.
    \item \textbf{Robotica}: uso di LLM per interpretare istruzioni linguistiche e guidare azioni fisiche.
\end{itemize}

\subsection{Agenti Autonomi e Tool Use}
Un campo emergente riguarda l'integrazione degli LLM in agenti autonomi:
\begin{itemize}
    \item \textbf{Tool-augmented LLMs}: modelli che interagiscono con strumenti esterni 
    come motori di ricerca, calcolatrici o database.
    \item \textbf{Agenti multi-step}: in grado di pianificare sequenze di azioni.
    \item Framework come \textit{LangChain}, \textit{AutoGPT} e \textit{BabyAGI} mostrano 
    le potenzialità degli LLM come agenti generici.
\end{itemize}

\newpage
\section{Sfide, Limitazioni ed Aspetti Etici}

Nonostante i notevoli progressi, gli LLM presentano ancora
numerose sfide tecniche, limitazioni pratiche e rischi etici.
Questo capitolo esamina i principali problemi legati alla loro adozione
e le preoccupazioni sociali connesse al loro utilizzo.

\subsection{Allucinazioni e Aderenza ai Fatti}
Gli LLM spesso generano contenuti plausibili ma falsi, un fenomeno noto come \textbf{allucinazioni}.
Possono inventare dati, riferimenti bibliografici o fatti storici inesistenti. Ciò riduce l'affidabilità in contesti critici 
come medicina, diritto o scienza. Tecniche come \textit{\textit{retrieval-augmented generation}} (RAG) sono state proposte per mitigare questo problema.

\subsection{Bias e Equità}
Gli LLM ereditano i bias presenti nei dati di addestramento.
\begin{itemize}
    \item Riproducono stereotipi di genere, etnia, religione, orientamento sessuale.
    \item Possono amplificare discriminazioni già esistenti nella società.
\end{itemize}
Sono in corso ricerche su dataset bilanciati e metodi di de-biasing.

\subsection{Sicurezza e Abusi Potenziali}
Gli LLM possono essere usati impropriamente per generare contenuti dannosi.
\begin{itemize}
    \item \textbf{Disinformazione}: generazione automatica di fake news e propaganda.
    \item \textbf{Cybersecurity}: creazione di codice malevolo o phishing su larga scala.
    \item \textbf{Deepfakes multimodali}: se integrati con modelli di immagini o audio.
\end{itemize}

\subsection{Interpretabilità e Trasparenza}
Un limite importante riguarda la natura \textbf{black-box} degli LLM.
\begin{itemize}
    \item È difficile spiegare come vengano prese le decisioni interne al modello.
    \item La mancanza di interpretabilità riduce la fiducia in applicazioni sensibili.
\end{itemize}
Sono state proposte tecniche di \textit{model probing}, analisi delle rappresentazioni interne e spiegazioni post-hoc.

\subsection{Sostenibilità e Impatto Ambientale}
Il training di LLM richiede un enorme consumo energetico.
\begin{itemize}
    \item Addestrare un singolo modello può generare tonnellate di CO$_2$.
    \item Questo solleva preoccupazioni ambientali e di sostenibilità.
\end{itemize}
Approcci di efficientamento (quantizzazione, pruning, distillazione) mirano a ridurre tali costi.

\subsection{Accessibilità e Disuguaglianze}
Gli LLM di punta sono sviluppati principalmente da grandi aziende tecnologiche.
\begin{itemize}
    \item L'alto costo computazionale limita la ricerca accademica indipendente.
    \item Si rischia una concentrazione di potere e conoscenza in poche mani.
\end{itemize}
Iniziative open-source (es. \textit{LLaMA}, \textit{Falcon}, \textit{MPT}) cercano di democratizzare l'accesso.

\subsection{Allineamento con Valori Umani}
Un'altra sfida riguarda l'\textbf{alignment} con preferenze etiche e valori umani.
\begin{itemize}
    \item Gli LLM devono essere utili, onesti e innocui.
    \item Tecniche come \textbf{RLHF} e \textbf{\textit{Constitutional AI}} sono state sviluppate 
    per migliorare l'allineamento.
    \item Rimane complesso garantire coerenza su culture e comunità diverse.
\end{itemize}

\subsection{Aspetti Legali e Regolamentazione}
Con la diffusione degli LLM emergono questioni legali:
\begin{itemize}
    \item \textbf{Copyright}: rischio di violazioni dovute a testi generati simili a fonti protette.
    \item \textbf{Privacy}: possibilità che vengano riprodotte informazioni sensibili dai dati di training.
    \item \textbf{Regolamentazione}: discussioni in corso a livello internazionale su AI Act e framework etici.
\end{itemize}

\newpage
\section{Prospettive Future e Direzioni di Ricerca}

Gli LLM rappresentano uno dei campi più dinamici dell'intelligenza artificiale. 
Dopo i progressi ottenuti negli ultimi anni, la comunità scientifica 
si interroga su come evolveranno i modelli futuri e quali direzioni di ricerca 
saranno più rilevanti. 
Questo capitolo discute le prospettive principali.

\subsection{Efficienza e Sostenibilità}
Una priorità sarà lo sviluppo di modelli più efficienti dal punto di vista computazionale e energetico.
\begin{itemize}
    \item Tecniche di compressione (quantizzazione, pruning, distillazione) sempre più sofisticate.
    \item Architetture ibride che combinano Transformer con nuovi meccanismi di attenzione.
    \item Algoritmi di addestramento ottimizzati per ridurre costi e tempi.
\end{itemize}

\subsection{Modelli Multimodali}
Gli LLM tenderanno a integrarsi con altre modalità sensoriali:
\begin{itemize}
    \item \textbf{Vision-Language Models}: unione di testo e immagini.
    \item \textbf{Speech e audio}: modelli in grado di comprendere e generare linguaggio parlato.
    \item \textbf{Video e robotica}: comprensione di sequenze visive e comandi linguistici per il controllo di agenti fisici.
\end{itemize}
L'obiettivo è costruire \textbf{modelli universali} in grado di gestire input multimodali.

\subsection{Memory-Augmented LLMs}
Attualmente gli LLM hanno memoria limitata alla finestra contestuale.
\begin{itemize}
    \item Ricerca su architetture con memoria esterna persistente.
    \item Meccanismi per richiamare informazioni apprese in sessioni precedenti.
    \item Possibilità di modelli che accumulano conoscenza nel tempo, riducendo la necessità di retraining massivo.
\end{itemize}

\subsection{Autonomia e Agenti Intelligenti}
Un filone emergente è l'integrazione degli LLM in agenti autonomi.
\begin{itemize}
    \item Capacità di pianificazione multi-step tramite prompting avanzato.
    \item Integrazione con tool esterni: database, motori di ricerca, calcolatrici, API.
    \item Applicazioni in domini complessi come finanza, ricerca scientifica, sviluppo software.
\end{itemize}

\subsection{Interpretabilità e Controllo}
La comunità scientifica riconosce la necessità di modelli più trasparenti:
\begin{itemize}
    \item Strumenti di \textbf{explainable AI} per comprendere le decisioni interne.
    \item Analisi delle rappresentazioni neurali per capire l'emergere delle abilità.
    \item Tecniche di controllo fine-grained per modulare il comportamento del modello.
\end{itemize}

\subsection{Sicurezza e Robustezza}
Un'altra direzione riguarda la costruzione di LLM affidabili e sicuri:
\begin{itemize}
    \item Difese contro attacchi avversari e prompt injection.
    \item Riduzione delle allucinazioni tramite retrieval e grounding su basi di conoscenza.
    \item Maggiore robustezza a input rumorosi o manipolati.
\end{itemize}

\subsection{Allineamento e Governance}
Il tema dell'allineamento con valori umani resterà centrale.
\begin{itemize}
    \item Evoluzione di tecniche come RLHF, Constitutional AI e feedback multimodale.
    \item Creazione di framework etici condivisi per la progettazione di modelli sicuri.
    \item Discussione su regolamentazione internazionale e open science.
\end{itemize}

\subsection{Verso l'Intelligenza Artificiale Generale (AGI)}
Infine, gli LLM sono considerati possibili passi verso l'AGI.
\begin{itemize}
    \item Studi sull'emergere di capacità generali di ragionamento e apprendimento.
    \item Integrazione con sistemi simbolici e neuro-simbolici.
    \item Possibilità di architetture future che superino i limiti dei Transformer attuali.
\end{itemize}